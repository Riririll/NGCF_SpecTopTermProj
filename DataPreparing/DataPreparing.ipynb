{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Clone repository จาก GitHub\n",
        "!git clone https://github.com/Riririll/NGCF_SpecTopTermProj.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HoGK0F7cf0d",
        "outputId": "c66cf6bf-fe2f-456f-e64d-11585e1249fc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NGCF_SpecTopTermProj'...\n",
            "remote: Enumerating objects: 398, done.\u001b[K\n",
            "remote: Counting objects: 100% (173/173), done.\u001b[K\n",
            "remote: Compressing objects: 100% (98/98), done.\u001b[K\n",
            "remote: Total 398 (delta 76), reused 166 (delta 71), pack-reused 225 (from 1)\u001b[K\n",
            "Receiving objects: 100% (398/398), 16.08 MiB | 15.36 MiB/s, done.\n",
            "Resolving deltas: 100% (149/149), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import random\n",
        "\n",
        "def filter_amazon_book(data_path, n_users=1000, n_items=7000, min_interactions=5):\n",
        "    # อ่านไฟล์ train.txt\n",
        "    with open(f\"{data_path}/train.txt\", 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    # แปลงข้อมูลเป็น DataFrame\n",
        "    interactions = []\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()  # split() จะแยกตามช่องว่าง\n",
        "        user = int(parts[0])          # user_id คือตัวแรก\n",
        "        items = list(map(int, parts[1:]))  # item_ids คือรายการที่เหลือ\n",
        "        for item in items:\n",
        "            interactions.append([user, item])\n",
        "\n",
        "    df = pd.DataFrame(interactions, columns=['user_id', 'item_id'])\n",
        "\n",
        "    # นับจำนวน interactions ต่อ user และ item\n",
        "    user_counts = df['user_id'].value_counts()\n",
        "    item_counts = df['item_id'].value_counts()\n",
        "\n",
        "    # เลือก users และ items ที่มี interactions มากที่สุด\n",
        "    selected_users = user_counts[user_counts >= min_interactions].head(n_users).index\n",
        "    selected_items = item_counts[item_counts >= min_interactions].head(n_items).index\n",
        "\n",
        "    # กรองข้อมูลให้เฉพาะ users และ items ที่เลือก\n",
        "    filtered_df = df[\n",
        "        (df['user_id'].isin(selected_users)) &\n",
        "        (df['item_id'].isin(selected_items))\n",
        "    ]\n",
        "\n",
        "    # สร้าง mapping ใหม่สำหรับ user_id และ item_id\n",
        "    user_map = {old_id: new_id for new_id, old_id in enumerate(sorted(filtered_df['user_id'].unique()))}\n",
        "    item_map = {old_id: new_id for new_id, old_id in enumerate(sorted(filtered_df['item_id'].unique()))}\n",
        "\n",
        "    # แปลง IDs\n",
        "    filtered_df['user_id'] = filtered_df['user_id'].map(user_map)\n",
        "    filtered_df['item_id'] = filtered_df['item_id'].map(item_map)\n",
        "\n",
        "    return filtered_df, user_map, item_map\n",
        "\n",
        "\n",
        "def filter_test_file(test_file, user_map, item_map, output_test_file):\n",
        "    # อ่านไฟล์ test.txt\n",
        "    with open(test_file, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    test_interactions = []\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()  # split() จะแยกตามช่องว่าง\n",
        "        user = int(parts[0])          # user_id คือตัวแรก\n",
        "        items = list(map(int, parts[1:]))  # item_ids คือรายการที่เหลือ\n",
        "        for item in items:\n",
        "            if user in user_map and item in item_map:  # กรองเฉพาะ user และ item ที่อยู่ใน mapping\n",
        "                test_interactions.append([user_map[user], item_map[item]])\n",
        "\n",
        "    # สร้าง DataFrame จากข้อมูลที่กรองแล้ว\n",
        "    test_df = pd.DataFrame(test_interactions, columns=['user_id', 'item_id'])\n",
        "\n",
        "    # บันทึกข้อมูลใน test.txt\n",
        "    test_data = test_df.groupby('user_id')['item_id'].agg(list)\n",
        "    with open(output_test_file, 'w') as f:\n",
        "        for user_id, items in test_data.items():\n",
        "            items_str = ' '.join(map(str, items))  # เปลี่ยนจากคอมม่าเป็นช่องว่าง\n",
        "            f.write(f\"{user_id} {items_str}\\n\")\n",
        "\n",
        "\n",
        "# สร้างไฟล์ใหม่\n",
        "def save_filtered_data(filtered_df, user_map, item_map, output_path):\n",
        "    # สร้าง train.txt\n",
        "    train_data = filtered_df.groupby('user_id')['item_id'].agg(list)\n",
        "    with open(f\"{output_path}/train.txt\", 'w') as f:\n",
        "        for user_id, items in train_data.items():\n",
        "            items_str = ' '.join(map(str, items))  # เปลี่ยนจากคอมม่าเป็นช่องว่าง\n",
        "            f.write(f\"{user_id} {items_str}\\n\")\n",
        "\n",
        "    # สร้าง user_list.txt\n",
        "    with open(f\"{output_path}/user_list.txt\", 'w') as f:\n",
        "        for old_id, new_id in user_map.items():\n",
        "            f.write(f\"{old_id} {new_id}\\n\")  # ใช้ช่องว่างเป็นตัวคั่น\n",
        "\n",
        "    # สร้าง item_list.txt\n",
        "    with open(f\"{output_path}/item_list.txt\", 'w') as f:\n",
        "        for old_id, new_id in item_map.items():\n",
        "            f.write(f\"{old_id} {new_id}\\n\")  # ใช้ช่องว่างเป็นตัวคั่น\n",
        "\n",
        "# กรองและบันทึกข้อมูล\n",
        "data_path = \"/content/NGCF_SpecTopTermProj/Data/amazon-book\"\n",
        "output_path = \"/content/NGCF_SpecTopTermProj/Data/amazon-book-small\"\n",
        "\n",
        "# สร้างโฟลเดอร์ใหม่\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "# กรองข้อมูลใน train.txt\n",
        "filtered_df, user_map, item_map = filter_amazon_book(data_path)\n",
        "save_filtered_data(filtered_df, user_map, item_map, output_path)\n",
        "\n",
        "# กรองและบันทึกข้อมูลใน test.txt\n",
        "test_file = f\"{data_path}/test.txt\"\n",
        "output_test_file = f\"{output_path}/test.txt\"\n",
        "filter_test_file(test_file, user_map, item_map, output_test_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXDcCLnpcbp3",
        "outputId": "808bb5f2-184d-4dfd-c7f4-f211ef83c98a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-83168eb7a93e>:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['user_id'] = filtered_df['user_id'].map(user_map)\n",
            "<ipython-input-2-83168eb7a93e>:43: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['item_id'] = filtered_df['item_id'].map(item_map)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "P09WRP6d6wMv"
      },
      "outputs": [],
      "source": [
        "# อ่านข้อมูลจาก item_list.txt และ user_list.txt\n",
        "item_map = {}\n",
        "user_map = {}\n",
        "\n",
        "# อ่าน item_list.txt (มีรูปแบบ (org_id, remap_id))\n",
        "with open(\"/content/NGCF_SpecTopTermProj/Data/amazon-book-small/item_list.txt\", \"r\") as f:\n",
        "    for line in f.readlines():\n",
        "        org_item_id, remap_item_id = map(int, line.strip().split())\n",
        "        item_map[org_item_id] = remap_item_id\n",
        "\n",
        "# อ่าน user_list.txt (มีรูปแบบ (org_id, remap_id))\n",
        "with open(\"/content/NGCF_SpecTopTermProj/Data/amazon-book-small/user_list.txt\", \"r\") as f:\n",
        "    for line in f.readlines():\n",
        "        org_user_id, remap_user_id = map(int, line.strip().split())\n",
        "        user_map[org_user_id] = remap_user_id\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# อ่านข้อมูลจาก train.txt และแปลงเป็น train.rating\n",
        "train_data = []\n",
        "\n",
        "with open(\"/content/NGCF_SpecTopTermProj/Data/amazon-book-small/train.txt\", \"r\") as f:\n",
        "    for line in f.readlines():\n",
        "        parts = line.strip().split()\n",
        "\n",
        "        # ID ใหม่ของ user และ item ที่ได้จาก train.txt\n",
        "        remapped_user_id = int(parts[0])  # userID ใหม่จาก train.txt\n",
        "        items = list(map(int, parts[1:]))  # itemIDs ใหม่จาก train.txt\n",
        "\n",
        "        # สำหรับแต่ละ item ที่ผู้ใช้มีการปฏิสัมพันธ์ จะสร้าง triplet (user, item, rating=1)\n",
        "        for item in items:\n",
        "            train_data.append((remapped_user_id, item, 1))  # rating=1 สำหรับ positive interaction\n",
        "\n",
        "# เขียนข้อมูลเป็น train.rating\n",
        "with open(\"train.rating\", \"w\") as f:\n",
        "    for userID, itemID, rating in train_data:\n",
        "        f.write(f\"{userID}\\t{itemID}\\t{rating}\\n\")\n",
        "\n",
        "print(f\"Number of training instances: {len(train_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6sHzztX8Tws",
        "outputId": "69d1888c-6481-4779-d059-6b3cfa5c51a5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training instances: 106055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# อ่านข้อมูลจาก test.txt และแปลงเป็น test.rating\n",
        "test_data = []\n",
        "\n",
        "with open(\"/content/NGCF_SpecTopTermProj/Data/amazon-book-small/test.txt\", \"r\") as f:\n",
        "    for line in f.readlines():\n",
        "        parts = line.strip().split()\n",
        "\n",
        "        # ID ใหม่ของ user และ item ที่ได้จาก test.txt\n",
        "        remapped_user_id = int(parts[0])  # userID ใหม่จาก test.txt\n",
        "        items = list(map(int, parts[1:]))  # itemIDs ใหม่จาก test.txt\n",
        "\n",
        "        # สำหรับแต่ละ item ที่ผู้ใช้มีการปฏิสัมพันธ์ จะสร้าง triplet (user, item, rating=1)\n",
        "        for item in items:\n",
        "            test_data.append((remapped_user_id, item, 1))  # rating=1 สำหรับ positive interaction\n",
        "\n",
        "# เขียนข้อมูลเป็น test.rating\n",
        "with open(\"test.rating\", \"w\") as f:\n",
        "    for userID, itemID, rating in test_data:\n",
        "        f.write(f\"{userID}\\t{itemID}\\t{rating}\\n\")\n",
        "\n",
        "print(f\"Number of test instances: {len(test_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WpNcv5q8XvL",
        "outputId": "4f48f449-eef2-4325-95f8-22f64e4a72e6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test instances: 17306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "num_items = 7000  # จำนวนไอเท็มทั้งหมด\n",
        "\n",
        "# ฟังก์ชันอ่านไฟล์ test.rating และสร้าง dictionary ที่เก็บ positive items\n",
        "def load_test_rating(file_path):\n",
        "    test_data = {}\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split(\"\\t\")\n",
        "            userID = int(parts[0])  # userID\n",
        "            itemID = int(parts[1])  # itemID\n",
        "            rating = float(parts[2])  # rating\n",
        "            if userID not in test_data:\n",
        "                test_data[userID] = set()\n",
        "            test_data[userID].add(itemID)\n",
        "    return test_data\n",
        "\n",
        "# ฟังก์ชันสร้าง negative samples จาก positive items\n",
        "def create_negative_samples(test_data, num_items):\n",
        "    negative_samples = []\n",
        "    for userID, pos_items in test_data.items():\n",
        "        # สำหรับแต่ละ positive item (userID, itemID), สุ่ม negative items\n",
        "        for itemID in pos_items:\n",
        "            # สุ่มเลือก negative items ที่ไม่ได้มีการปฏิสัมพันธ์\n",
        "            available_items = set(range(1, num_items + 1)) - pos_items\n",
        "            negative_items = random.sample(available_items, 99)  # สุ่ม 99 negative items\n",
        "            # สร้าง (userID, itemID) และตามด้วย 99 negative items\n",
        "            negative_samples.append((userID, itemID, negative_items))\n",
        "    return negative_samples\n",
        "\n",
        "# ฟังก์ชันเขียน negative samples ลงในไฟล์ test.negative\n",
        "def write_negative_samples(negative_samples, output_file):\n",
        "    with open(output_file, \"w\") as f:\n",
        "        for userID, itemID, neg_items in negative_samples:\n",
        "            f.write(f\"({userID},{itemID})\\t\" + \"\\t\".join(map(str, neg_items)) + \"\\n\")\n",
        "\n",
        "input_file = \"test.rating\"  # ไฟล์ input test.rating\n",
        "output_file = \"test.negative\"  # ไฟล์ output test.negative\n",
        "\n",
        "# อ่านข้อมูลจาก test.rating\n",
        "test_data = load_test_rating(input_file)\n",
        "\n",
        "# สร้าง negative samples\n",
        "negative_samples = create_negative_samples(test_data, num_items)\n",
        "\n",
        "# เขียน negative samples ลงใน test.negative\n",
        "write_negative_samples(negative_samples, output_file)\n",
        "\n",
        "print(f\"Number of negative samples generated: {len(negative_samples)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa8C4NVz8Z-c",
        "outputId": "fe446ad6-4c4c-4482-bf90-cbb726515794"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-dc3e1889e68d>:27: DeprecationWarning: Sampling from a set deprecated\n",
            "since Python 3.9 and will be removed in a subsequent version.\n",
            "  negative_items = random.sample(available_items, 99)  # สุ่ม 99 negative items\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of negative samples generated: 17306\n"
          ]
        }
      ]
    }
  ]
}
